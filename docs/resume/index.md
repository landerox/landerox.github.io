---
hide:
  - toc
icon: material/file-document
---

# :material-file-document: Professional Experience

> **Senior Data Engineer** with **6+ years** of experience designing scalable data platforms on Google Cloud. Specialized in transitioning enterprises from legacy ETL to modern DataOps & MLOps architectures.

---

## :material-briefcase: Work History

### **[TCS Chile](https://www.tcs.com/){ target="_blank" }**

**Senior Consultant**
<small>:material-calendar: Jul 2025 – Present &nbsp; | &nbsp; :material-map-marker: Santiago, Chile</small>

Focused on MLOps automation and enhancing data science workflows within Vertex AI.

* :material-robot: **MLOps & Automation:** Automating Vertex AI notebooks and maintaining reusable CI/CD workflows to streamline model training pipelines.
* :material-graph: **Graph Data Engineering:** Managing data modeling in **Neo4j** for complex relationship analysis, integrating graph results back into BigQuery.
* :material-shield-check: **Model Governance:** Implementing dataset versioning and drift monitoring practices to ensure regulatory compliance.

---

### **[AXITY](https://www.axity.com/){ target="_blank" }**

**Senior Consultant**
<small>:material-calendar: Jul 2024 – Jul 2025 &nbsp; | &nbsp; :material-map-marker: Santiago, Chile</small>

Led the infrastructure setup and pipeline modernization for cloud data initiatives.

* :material-terraform: **Infrastructure as Code:** Architected and configured GCP projects (IAM, Security, Networking) using **Terraform**, ensuring governance from day one.
* :material-pipe: **Pipeline Architecture:** Designed ELT processes using **Cloud Functions** and **Dataflow**, optimizing for event-driven ingestion.
* :material-speedometer: **Optimization:** Refactored legacy SQL workloads in BigQuery, implementing partitioning and clustering strategies that reduced query costs.

---

### **[ACID LABS](https://acidlabs.com/){ target="_blank" }**

**Senior Data Engineer**
<small>:material-calendar: Feb 2023 – Feb 2024 &nbsp; | &nbsp; :material-map-marker: Santiago, Chile</small>

Responsible for robust data ingestion at scale and democratizing data models.

* :material-database-search: **Data Modeling (dbt):** Led the transformation layer using **dbt** with BigQuery, establishing testing standards and documentation for new datasets.
* :material-kubernetes: **Container Orchestration:** Managed **Kubernetes** deployments for data collectors, ensuring high availability for data pipelines.
* :material-test-tube: **Automation:** Developed automated Python tests for pipeline reliability and created parquet-based backup systems using Docker.

---

### **[SODIMAC](https://sodimac.falabella.com/){ target="_blank" }**

**Senior Data Engineer** *(Digital Algorithms Team)*
<small>:material-calendar: Jan 2022 – Jan 2023 &nbsp; | &nbsp; :material-map-marker: Santiago, Chile</small>

* :material-music-note-eighth: **Orchestration:** Implemented scalable pipelines using **Cloud Composer (Airflow)** to centralize data ingestion from diverse sources.
* :material-chart-line: **ML Deployment:** Supported the deployment of Cross-sell and Up-sell recommendation models to production.

---

### **[NTT DATA](https://www.nttdata.com/){ target="_blank" }**

**Data Engineer**
<small>:material-calendar: Dec 2019 – Dec 2021 &nbsp; | &nbsp; :material-map-marker: Santiago, Chile</small>

* :material-cloud-upload: **Cloud Migration:** Executed the migration of on-premise data systems (Hadoop/Spark) to Google Cloud Platform.
* :material-monitor-dashboard: **Visualization:** Built Looker dashboards to expose key business metrics to stakeholders.
